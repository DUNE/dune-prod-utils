[global]
group      = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
version = v07_06_00
quals   = e17:prof
utilversion = v07_06_00
utilquals   = %(quals)s
anaversion = %(version)s
basename  = np04_keepup
fclfile = prodgenie_%(basename)s_dune10kt_1x2x6.fcl
anafclfile = override_me
outdir = /pnfs/dune/scratch/dunepro/dropbox/mcc11/%(basename)s
logdir = /pnfs/dune/scratch/dunepro/test_MCC11/logs/%(basename)s
tardir = /pnfs/dune/resilient/users/dunepro
out_ana_dir = override_me
#tarfile = override_me
datastream = override_me
pandoradir= /pnfs/dune/scratch/dunepro/dropbox/PDSPProd2/PandoraFiles
campaign = PDSPProd4
tarname = override_me
declare_metadata = True
nevents= -1

[env_pass]
#IFDH_DEBUG = 1
SAM_EXPERIMENT=%(experiment)s
SAM_GROUP=%(group)s
SAM_STATION=%(experiment)s
IFDH_CP_MAXRETRIES=2
XRD_CONNECTIONRETRY=32
XRD_REQUESTTIMEOUT=14400
XRD_REDIRECTLIMIT=255
XRD_LOADBALANCERTTL=7200
XRD_STREAMTIMEOUT=14400

[submit]
G          = %(group)s
subgroup   = prod_keepup
N          = 1
#N          = 10
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
cpu                    = 1
expected-lifetime      = 5h
#timeout		       = None
disk                  = 20GB
memory                 = 2500MB
#memory                 = 4000MB
#OS = SL7
email-to               = kherner@fnal.gov

#If we need tar files
#append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=883\)\&\&\(TARGET.HAS_cvmfs_fifeuser1_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser2_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser3_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser4_opensciencegrid_org==true\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)

# we do not need tar files
append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_fermilab_opensciencegrid_org_REVISION\>=9822\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=1015\)\&\&\(TARGET.HAS_SINGULARITY==true\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)
lines_1    = +SingularityImage=\\\"/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest\\\"
lines_2    = +FERMIHTC_AutoRelease=True
lines_3    = +FERMIHTC_GraceMemory=2000
lines_4    = +FERMIHTC_GraceLifetime=86400
mail_never                 = True
#site       = CERN,FermiGrid,FNAL,Caltech,London,Sheffield,Nebraska,Omaha,BU,Michigan,BNL,UCSD,Liverpool,Manchester,Lancaster,SGridOxford,RAL,Florida,SGridECDF,CCIN2P3,FZU,Colorado
# smaller than usual site list because we ask for 3500MB and 35 run time by default
site       = BNL,BR_CBPF,Bristol,CA_Victoria,CCIN2P3,CERN,Clemson,Colorado,FermiGrid,Florida,FZU,JINR_CLOUD,Lancaster,Liverpool,London,London_QMUL,Manchester,NotreDame,Omaha,PIC,RAL,SGrid,SGridECDF,SGridOxford,Sheffield,SURFsara,UCSD,Wisconsin
#f_0 = %(tardir)s/%(tarfile)s

[job_setup]
#debug       = True
find_setups = True
source_1    = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
setup_1     = dunetpc %(version)s -q %(quals)s
setup_2     = protoduneana %(anaversion)s -q %(quals)s
setup_3     = duneutil %(utilversion)s -q %(utilquals)s
setup_4     = dune_oslibs v1_0_0
multifile   = False
#prescript_1 = ln -s ${CONDOR_DIR_INPUT}/%(fclfile)s .
prescript_1 = sed -e "s/\"DUNE_CERN_SEP2018\"/\"DUNE_CERN_SEP2018_ANALYSIS\"/" ${DUNETPC_DIR}/job/BeamEvent.fcl > ./BeamEvent.fcl
prescript_2 = echo ""
postscript_1 = cp ${JSB_TMP}/JOBSUB_LOG_FILE ./%(basename)s_${CLUSTER}_${PROCESS}.out
postscript_2 = cp ${JSB_TMP}/JOBSUB_ERR_FILE ./%(basename)s_${CLUSTER}_${PROCESS}.err
postscript_3 = extractor_prod.py --infile $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s > $(ls *_reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root).json 
postscript_5 = mv Pandora_Events.pndr $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root | sed -e "s/\.root/_Pandora_Events\.pndr/")
#postscript_6 = mv $(ls hist_*reco.root) $(ls hist_*_reco.root | sed -e "s/\.root/_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}\.root/")
# pandora_metadta with --requestid only available as of v08_60_00
postscript_6 = pandora_metadata.py --infile $(ls *_Pandora_Events.pndr)  --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *_reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root.json) > $(ls *_Pandora_Events.pndr).json
postscript_7 = ls ./

export       = FILETIMESTAMP=$(date -u +%%Y%%m%%dT%%H%%M%%SZ)
userscript   = True
ifdh_art     = True

[sam_consumer]
limit       = 1
appvers	    = %(version)s
schema      = root
appname     = reco
appfamily   = art

[executable]
name      = lar
arg_1     = -c
arg_2     = %(fclfile)s
arg_3     = -o
arg_4     = %%ifb_reco1_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root
arg_5     = -n
arg_6     = %(nevents)s
# disable the sam stream name setting as on 2018-09-20 since it gets set in the raw file now.
#arg_3     = --sam-stream-name=%(datastream)s


[job_output]
addoutput = np04*_reco*Z.root
#rename      = unique
dest          = %(outdir)s
declare_metadata = $(declare_metadata)s
metadata_extractor = json
add_location = False


[job_output_1]
addoutput = *_Pandora_Events.pndr
dest          = %(pandoradir)s
declare_metadata = $(declare_metadata)s
metadata_extractor = json
add_location = False


[stage_reco2]
#job_setup.prescript_2 = sed -e "s/\"dataTier:  "full-reconstructed"\"/\"dataTier: "reco-recalibrated"\"/" ${DUNETPC_DIR}/job/protoDUNE_SP_keepup_decoder_reco_stage2.fcl > ./protoDUNE_SP_keepup_decoder_reco_stage2.fcl
job_setup.prescript_2 = sed -e "/dataTier:/ s/full-reconstructed/reco-recalibrated/" ${DUNETPC_DIR}/job/%(fclfile)s > ./%(fclfile)s
job_setup.postscript_3 = extractor_prod.py --infile $(ls *reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s > $(ls *_reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root).json 
job_setup.postscript_4 = mv michelremoving.root $(ls *reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root | sed -e "s/\.root/_michelremoving.root/") 
job_setup.postscript_5 = mv Pandora_Events.pndr $(ls *reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root | sed -e "s/\.root/_Pandora_Events\.pndr/")
job_setup.postscript_7 = pandora_metadata.py --infile $(ls *_Pandora_Events.pndr)  --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *_reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root.json) > $(ls *_Pandora_Events.pndr).json
job_setup.postscript_8 = pandora_metadata.py --infile $(ls *_michelremoving.root)  --appfamily art --appname calana --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *_reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root.json) --data_tier root-tuple --file_format rootntuple --strip_parents > $(ls *_michelremoving.root).json
job_setup.postscript_9 = sed -i -e "/file_name/ a     \"parents\": [\"$(ls *reco2_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root)\"]," $(ls *_michelremoving.root).json
executable.arg_4     = %%ifb_reco2_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root
executable_1.arg_4 = \*_reco2_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root

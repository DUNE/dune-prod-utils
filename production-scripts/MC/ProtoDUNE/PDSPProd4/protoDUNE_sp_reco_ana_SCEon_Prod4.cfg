[global]
group      = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
version = v07_06_00
quals   = e17:prof
utilversion = v07_06_00
utilquals   = %(quals)s
anaversion = %(version)s
basename  = np04_keepup
fclfile = prodgenie_%(basename)s_dune10kt_1x2x6.fcl
anafclfile = override_me
campaign = PDSPProd4
basename  = %(campaign)s_protoDUNE_sp_g4_p%(pbeam)sGeV
reconame = %(campaign)s_protoDUNE_sp_reco_stage1_p%(pbeam)sGeV
ananame =  %(campaign)s_protoDUNE_sp_ana_p%(pbeam)sGeV
pandoradir= /pnfs/dune/scratch/dunepro/dropbox/%(campaign)s/PandoraFiles_mcc
outdir = /pnfs/dune/scratch/dunepro/dropbox/mcc11/%(basename)s
logdir = /pnfs/dune/scratch/dunepro/test_MCC11/logs/%(basename)s
tardir = /pnfs/dune/resilient/users/dunepro
out_reco_dir = override_me
out_ana_dir = override_me
#tarfile = override_me
datastream = override_me
pandoradir= /pnfs/dune/scratch/dunepro/dropbox/PDSPProd2/PandoraFiles
campaign = PDSPProd4
tarname = override_me

[env_pass]
#IFDH_DEBUG = 1
SAM_EXPERIMENT=%(experiment)s
SAM_GROUP=%(group)s
SAM_STATION=%(experiment)s
IFDH_CP_MAXRETRIES=2
XRD_CONNECTIONRETRY=32
XRD_REQUESTTIMEOUT=14400
XRD_REDIRECTLIMIT=255
XRD_LOADBALANCERTTL=7200
XRD_STREAMTIMEOUT=14400

[submit]
G          = %(group)s
subgroup   = prod_keepup
N          = 1
#N          = 10
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
cpu                    = 1
expected-lifetime      = 5h
#timeout		       = None
disk                  = 20GB
memory                 = 2500MB
#memory                 = 4000MB
#OS = SL7
email-to               = kherner@fnal.gov

#If we need tar files
#append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=883\)\&\&\(TARGET.HAS_cvmfs_fifeuser1_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser2_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser3_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser4_opensciencegrid_org==true\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)

# we do not need tar files
append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_fermilab_opensciencegrid_org_REVISION\>=9822\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=1015\)\&\&\(TARGET.HAS_SINGULARITY==true\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)
lines_1    = +SingularityImage=\\\"/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest\\\"
lines_2    = +FERMIHTC_AutoRelease=True
lines_3    = +FERMIHTC_GraceMemory=2000
lines_4    = +FERMIHTC_GraceLifetime=86400
mail_never                 = True
#site       = CERN,FermiGrid,FNAL,Caltech,London,Sheffield,Nebraska,Omaha,BU,Michigan,BNL,UCSD,Liverpool,Manchester,Lancaster,SGridOxford,RAL,Florida,SGridECDF,CCIN2P3,FZU,Colorado
# smaller than usual site list because we ask for 3500MB and 35 run time by default
site       = BNL,BR_CBPF,Bristol,CA_Victoria,CCIN2P3,CERN,Clemson,Colorado,FermiGrid,Florida,FZU,JINR_CLOUD,Lancaster,Liverpool,London,London_QMUL,Manchester,NotreDame,Omaha,PIC,RAL,SGrid,SGridECDF,SGridOxford,Sheffield,SURFsara,UCSD,Wisconsin
#f_0 = %(tardir)s/%(tarfile)s

[job_setup]
#debug       = True
find_setups = True
source_1    = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
setup_1     = dunetpc %(version)s -q %(quals)s
setup_2     = protoduneana %(anaversion)s -q %(quals)s
setup_3     = duneutil %(utilversion)s -q %(utilquals)s
setup_4     = dune_oslibs v1_0_0
multifile   = False
#prescript_1 = ln -s ${CONDOR_DIR_INPUT}/%(fclfile)s .
prescript_1 = sed -e "s/\"DUNE_CERN_SEP2018\"/\"DUNE_CERN_SEP2018_ANALYSIS\"/" ${DUNETPC_DIR}/job/BeamEvent.fcl > ./BeamEvent.fcl
#prescript_1 = tar xzfp ${CONDOR_DIR_INPUT}/%(tarfile)s
#following prescripts borrowed from MC
prescript_2 = for fclfile in %(fclfile)s; do if [ ! -f ${fclfile} ]; then cp ${DUNETPC_DIR}/job/${fclfile} . ; fi ; echo 'services.FileCatalogMetadata.runType: "protodune-sp"' >> ${fclfile} ; done
prescript_3 = cp ${PROTODUNEANA_DIR}/job/%(anafclfile)s .; echo 'services.FileCatalogMetadata.runType: "protodune-sp"' >> %(anafclfile)s

postscript_1 = printf '{ "DUNE_MC.detector_type": "protoDUNE SP", "DUNE_MC.electron_lifetime": "35ms", "DUNE_MC.with_cosmics": 1, "MC.with_cosmics": 1, "DUNE_MC.beam_energy": %(pbeam)s, "beam.momentum": %(pbeam)s, "beam.polarity": 1, "DUNE_MC.liquid_flow": "no", "MC.liquid_flow": "no",\n"DUNE_MC.space_charge": "no", "MC.space_charge": "no"}\n' > common_sce_off.json #check the end of this one
postscript_2 = cp ${JSB_TMP}/JOBSUB_LOG_FILE ./%(basename)s_${CLUSTER}_${PROCESS}.out
postscript_3 = cp ${JSB_TMP}/JOBSUB_ERR_FILE ./%(basename)s_${CLUSTER}_${PROCESS}.err
postscript_4 = extractor_prod.py --infile $(ls *%(reconame)s_35ms_sce_datadriven_*_${FILETIMESTAMP}.root) --no_crc --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --requestid %(requestid)s --input_json common_sce_datadriven.json > $(ls *%(reconame)s_35ms_sce_datadriven_*_${FILETIMESTAMP}.root).json
#postscript_3 = extractor_prod.py --infile $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s  > $(ls *_reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root).json 
postscript_5 = mv michelremoving.root $(ls *%(reconame)s_35ms_sce_datadriven_*_${FILETIMESTAMP}.root | sed -e "s/\.root/_michelremoving.root/")
#postscript_5 = mv michelremoving.root $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root | sed -e "s/\.root/_michelremoving.root/") 
#postscript_6 = mv Pandora_Events.pndr $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root | sed -e "s/\.root/_Pandora_Events\.pndr/")
postscript_6 = mv $(ls hist_*reco.root) $(ls hist_*_reco.root | sed -e "s/\.root/_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}\.root/")
# pandora_metadta with --requestid only available as of v08_60_00
#postscript_7 = pandora_metadata.py --infile $(ls *_Pandora_Events.pndr)  --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *_reco1_*_${FILETIMESTAMP}.root.json) > $(ls *_Pandora_Events.pndr).json
postscript_7 = pandora_metadata.py --infile $(ls *_michelremoving.root)  --appfamily art --appname calana --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *%(reconame)s_*_${FILETIMESTAMP}.root.json) --data_tier root-tuple --file_format rootntuple --strip_parents > $(ls *_michelremoving.root).json
postscript_8 = sed -i -e "/file_name/ a     \"parents\": [\"$(ls *%(reconame)s_*_${FILETIMESTAMP}.root)\"]," $(ls *_michelremoving.root).json

export       = FILETIMESTAMP=$(date -u +%%Y%%m%%dT%%H%%M%%SZ)
userscript   = True
ifdh_art     = True



[sam_consumer]
limit       = 1
appvers	    = %(version)s
schema      = root
appname     = reco
appfamily   = art

[executable] # original
name      = lar
arg_1     = -c
arg_2     = %(fclfile)s
arg_3     = -o
arg_4     = %(reconame)s_35ms_sce_datadriven_%%r_%%s_\\\\\\\${FILETIMESTAMP}.root
# disable the sam stream name setting as on 2018-09-20 since it gets set in the raw file now.
#arg_3     = --sam-stream-name=%(datastream)s

#[executable_1]
#name      = mv
#arg_1     = Pandora_Events.pndr
#arg_2     = %(reconame)s_35ms_sce_datadriven_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}_Pandora_Events.pndr

[executable_1] # original
name = lar
arg_1 = -c
arg_2 = %(anafclfile)s
arg_3 = -s
arg_4 = \*%(reconame)s_35ms_sce_datadriven\*.root

[job_output]
addoutput = *%(reconame)s_35ms_sce_datadriven*Z.root
dest          = %(out_reco_dir)s
declare_metadata = True
metadata_extractor = json
add_location = False
launch_dest_check = False

#[job_output_1]
#addoutput = *%(basename)s*.out
##rename      = unique
#dest         = %(logdir)s
#declare_metadata = False
#add_location = False
#
#[job_output_2]
#addoutput = *%(basename)s*.err
#dest         = %(logdir)s
#declare_metadata = False
#add_location = False

[job_output_1]
addoutput = *_Pandora_Events.pndr
dest          = %(pandoradir)s
declare_metadata = True
metadata_extractor = json
add_location = False

[job_output_2]
addoutput = *_michelremoving.root
dest          = %(out_ana_dir)s
declare_metadata = True
metadata_extractor = json
add_location = False

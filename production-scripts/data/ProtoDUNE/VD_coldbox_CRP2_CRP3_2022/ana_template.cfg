[global]
group      = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
version = v09_17_01
quals   = e19:prof
utilversion = v09_16_01
utilquals   = e19:prof
basename = generic
#tailname = reco
tailname = anatree
outname = %(basename)s%(tailname)s
recofclfile = reco.fcl
anafclfile = override_me
#it is expected that the user will configure this with an over ride flag.
nevents = 1
#It is expected that the user will configure this with an over ride flag.
tardir = /pnfs/dune/persistent/dunepro/work/coldbox
tarfile = file_name
logdir  = generic
#It is expected that the user will configure this with an over ride flag. 
nskip  = 0
site_prefix = ThisMustBeOverridden
campaign = override_me
 

[env_pass]
#IFDH_DEBUG = 1
SAM_EXPERIMENT=%(experiment)s
SAM_GROUP=%(group)s
SAM_STATION=%(experiment)s
IFDH_CP_MAXRETRIES=2
XRD_CONNECTIONRETRY=32
XRD_REQUESTTIMEOUT=3600
XRD_REDIRECTLIMIT=255

[submit]
G          = %(group)s
subgroup   = prod_keepup
N          = 1
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
expected-lifetime      = 1h
disk                  = 30GB
memory                 = 4000MB
cpu                    = 2
# We want to use rucio - so sl7 only
# OS = SL6,SL7
OS = SL7
email-to               = kherner@fnal.gov
append_condor_requirements =  \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=915\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)
dataset                = ThisMustBeOverridden
#f_0 = %(tardir)s/%(tarfile)s
lines_1    = +SingularityImage=\\\"/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest\\\"
lines_2    = +FERMIHTC_AutoRelease=True
lines_3    = +FERMIHTC_GraceLifetime=172800
lines_4    = +FERMIHTC_GraceMemory=2500
# /pnfs/dune/resilient/users/dunepro/%(metadata_extractor)s
#site       = 
#BNL,BR_CBPF,Bristol,Caltech,CCIN2P3,CERN,CIEMAT,Clemson,Colorado,FermiGrid,Florida,FNAL,Lancaster,Lincoln,Liverpool,London,London_QMUL,Manchester,Michigan,Nebraska,NI#KHEF,NotreDame,Omaha,PIC,PuertoRico,RAL,SGrid,SGridECDF,SGridOxford,Sheffield,SU-ITS,SURFsara,UCSD,Wisconsin
#site = CCIN2P3,FermiGrid,NIKHEF,SURFsara,BNL

[job_setup]
#debug       = True
find_setups = True
source_1    = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh 
setup_1     = dunesw %(version)s -q %(quals)s 
multifile   = False
#prescript_1 = tar xzpf ${CONDOR_DIR_INPUT}/%(tarfile)s
##prescript_1= ifdh cp -D /pnfs/dune/persistent/dunepro/work/coldbox/standard_anatree_vdcb1_data.fcl .
ifdh_art    = True
#postscript_1 = pandora_metadata.py --infile $(ls *%(tailname)s_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) --no_crc --appname anatree --data_tier root-tuple --file_format rootntuple  --file_type binary --appversion %(version)s --appfamily art --campaign %(campaign)s > $(ls *%(tailname)s_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root).json

#postscript_3 = PYTHONHOME="" LD_LIBRARY_PATH=$(dropit -p "${LD_LIBRARY_PATH}" ${PYTHON_LIB}) ifdh cp -D $(ls *%(tailname)s_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) srm://ccsrm02.in2p3.fr:8443/pnfs/in2p3.fr/data/dune/prodtest/

#postscript_3 = ./copy_IN2P3.sh %(site_prefix)s
#postscript_3 = source /cvmfs/fermilab.opensciencegrid.org/products/common/other/rucio-client/sl7/1.19/bin/activate
#postscript_4 = export OLD_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
#postscript_5 = export LD_LIBRARY_PATH=$(dropit -p "${LD_LIBRARY_PATH}" ${PYTHON_LIB})
#postscript_6 = ifdh cp -D $(ls *%(tailname)s_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) srm://ccsrm02.in2p3.fr:8443/pnfs/in2p3.fr/data/dune/prodtest/
#postscript_7 = export LD_LIBRARY_PATH=$OLD_LD_LIBRARY_PATH
#postscript_8 = export PYTHONHOME=
#postscript_9 = setup dunetpc %(version)s -q %(quals)s

export       = FILETIMESTAMP=$(date -u +%%Y-%%m-%%dT%%H%%M%%SZ)


[sam_consumer]
limit       = 1
appvers	    = %(version)s
schema      = root
appname     = reco
appfamily   = art

#[executable]
#name      = lar
#arg_1     = -c
#arg_2     = %(recofclfile)s
#arg_3     = -o
#arg_4     = %%ifb_%(tailname)s_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root
##arg_4     = %%ifb_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}_%(tailname)s.root
#arg_5     = -T
#arg_6     = hist.root
##arg_7     = -n
##arg_8     = 10

[executable]
name      = lar
arg_1     = -c
arg_2     = %(anafclfile)s
arg_3     = -T 
#arg_4     = ntuple.root
arg_4     = %%ifb_%(tailname)s_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root
#arg_3     = -o
#arg_4     = merged_\${CLUSTER}_\${PROCESS}_\\\\\\\${FILETIMESTAMP}.root



[job_output]
addoutput = *_%(tailname)s_*.root
dest         = /path/to/out
declare_metadata = False
#declare_metadata = True
#metadata_extractor = json
add_location = False
#
#[job_output_2]
#addoutput = *%(basename)s*.err
##rename      = unique
#dest         = %(logdir)s
#declare_metadata = False
#add_location = False
